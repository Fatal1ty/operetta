<div align="center">

###### Build apps. Zero fuss.

[![Build Status](https://github.com/Fatal1ty/operetta/workflows/tests/badge.svg)](https://github.com/Fatal1ty/operetta/actions)
[![Latest Version](https://img.shields.io/pypi/v/operetta.svg)](https://pypi.python.org/pypi/operetta)
[![Python Version](https://img.shields.io/pypi/pyversions/operetta.svg)](https://pypi.python.org/pypi/operetta)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
</div>

# Operetta

A lightweight framework for building Python applications that is not tied to a specific transport protocol. It is built on top of [aiomisc](https://github.com/aiokitchen/aiomisc) (service lifecycle, entrypoint) and [dishka](https://github.com/reagento/dishka) (dependency injection). On top of that, the following integrations are available:

- AIOHTTP: declarative handlers with DI for request body, query, and path params; automatic OpenAPI generation with [Swagger](https://github.com/swagger-api/swagger-ui) and [Redoc](https://github.com/Redocly/redoc).
- PostgreSQL via [asyncpg](https://github.com/MagicStack/asyncpg): a database adapter and DI provider for a connection pool.
- PostgreSQL with HA via [hasql](https://github.com/aiokitchen/hasql): a pool with balancing, failover and the same adapter layer.


## Table of contents

- [Highlights](#highlights)
- [Installation](#installation)
- [Quickstart (HTTP API)](#quickstart-http-api)
  - [How it works under the hood](#how-it-works-under-the-hood)
- [Quickstart (non-HTTP app)](#quickstart-non-http-app)
- [Services and DI](#services-and-di)
- [PostgreSQL](#postgresql)
  - [Single-node PostgreSQL (asyncpg)](#single-node-postgresql-asyncpg)
  - [High-availability PostgreSQL cluster (hasql)](#high-availability-postgresql-cluster-hasql)
  - [Advanced setup](#advanced-setup)
- [Error handling and response format](#error-handling-and-response-format)

## Highlights

- Services as units of functionality: each service starts/stops via aiomisc and may provide DI providers.
- Single DI container ([dishka](https://github.com/reagento/dishka)) for the whole app; separate [scopes](https://dishka.readthedocs.io/en/stable/advanced/scopes.html) for APP and REQUEST.
- [AIOHTTP](https://github.com/aio-libs/aiohttp) integration:
  - Handler parameter annotations: `FromBody[T]`, `FromQuery[T]`, `FromPath[T]`.
  - Automatic parsing and validation via [mashumaro](https://github.com/Fatal1ty/mashumaro); friendly error details.
  - Unified JSON envelope for responses: `{success, data, error}`.
  - OpenAPI generation with static assets for Swagger/Redoc.
- PostgreSQL integrations ([asyncpg](https://github.com/MagicStack/asyncpg)/[hasql](https://github.com/aiokitchen/hasql)): interface adapter `PostgresDatabaseAdapter` + transactional `PostgresTransactionDatabaseAdapter` for repositories and units of work.

## Installation

Requires Python 3.10+.

- Base:

```bash
pip install operetta
```

- With AIOHTTP and OpenAPI:

```bash
pip install 'operetta[aiohttp]'
```

- With PostgreSQL via asyncpg:

```bash
pip install 'operetta[asyncpg]'
```

- With PostgreSQL HA via hasql:

```bash
pip install 'operetta[hasql]'
```

## Quickstart (HTTP API)

A minimal AIOHTTP app with DI and autogenerated OpenAPI. You are free to organize your project structure and files as you prefer.

```python
from dataclasses import dataclass, asdict
from aiohttp import web
from operetta.app import Application
from operetta.integrations.aiohttp.annotations import (
    FromBody,
    FromPath,
    FromQuery,
)
from operetta.integrations.aiohttp.response import success_response
from operetta.integrations.aiohttp.service import AIOHTTPService


@dataclass
class CreateUserBody:
    name: str
    email: str


@dataclass
class UserDto:
    id: int
    name: str
    email: str


async def create_user(
    _: web.Request, body: FromBody[CreateUserBody]
) -> web.StreamResponse:
    # ... create a user ...
    user = UserDto(id=1, name=body.name, email=body.email)
    return success_response(asdict(user))


async def get_user(
    _: web.Request,
    user_id: FromPath[int],
    detailed: FromQuery[bool] = False,
) -> UserDto:
    # ... load a user ...
    user = UserDto(id=user_id, name="Alice", email="alice@example.com")
    return user


routes = [
    web.post("/users", create_user),
    web.get("/users/{user_id}", get_user),
]

app = Application(
    AIOHTTPService(
        port=8080,
        routes=routes,
        docs_title="Demo API",
        docs_servers=("http://127.0.0.1:8080",),
        docs_default_type="swagger",  # or "redoc"
    ),
    di_providers=[],  # your dishka providers if needed
    warmup_dependencies=True,
)

if __name__ == "__main__":
    app.run()
```

Open the docs at:

- OpenAPI spec: `/static/openapi/openapi.yaml` (static files path is configurable).
- Swagger UI: `/docs/swagger` (and redirect from `/docs`).
- Redoc: `/docs/redoc`.

### How it works under the hood

- `AIOHTTPService` at app creation time:
  - Wraps your routes by inspecting handler signatures and `FromBody/FromQuery/FromPath` annotations.
  - Injects parsed values into the handler call.
  - If the return type is not a `StreamResponse`, serializes result into `SuccessResponse[T]` and returns JSON.
  - Builds the OpenAPI spec via [openapify](https://github.com/Fatal1ty/openapify) and serves it as static.
  - Attaches system middleware: DDD error mapping to HTTP and a global unhandled error catcher.
- DI is configured via [dishka integration with AIOHTTP](https://dishka.readthedocs.io/en/stable/integrations/aiohttp.html); the container is created by [`DIService`](https://github.com/Fatal1ty/operetta/blob/main/operetta/service/di.py) and wired into the app.
  - Each request gets a new DI scope (REQUEST) for per-request dependencies.
  - Handler parameters may be any DI-resolvable type (e.g., services, database adapters) in addition to `FromBody/FromQuery/FromPath` via `FromDishka`

## Quickstart (non-HTTP app)

Operetta is not tied to HTTP. You can write background services/workers on `aiomisc` and use DI:

```python
import asyncio
import contextlib
from operetta.app import Application
from operetta.service.base import Service

class Worker(Service):
    async def start(self):
        # example: a periodic task
        self._task = asyncio.create_task(self._job())

    async def stop(self, exception: Exception | None = None):
        self._task.cancel()
        with contextlib.suppress(Exception):
            await self._task

    async def _job(self):
        while True:
            # get dependencies if needed:
            # db = await self.get_dependency(PostgresDatabaseAdapter)
            await asyncio.sleep(1)

app = Application(Worker(), warmup_dependencies=True)
app.run()
```

## Services and DI

- Base service class: [`operetta.service.base.Service`](https://github.com/Fatal1ty/operetta/blob/main/operetta/service/base.py) (inherits `aiomisc.Service`).
- DI container: created inside `DIService` (see [`operetta/service/di.py`](https://github.com/Fatal1ty/operetta/blob/main/operetta/service/di.py)).
  - Providers are collected from:
    - the `Application` itself (argument `di_providers`),
    - application services implementing `get_di_providers()`.
  - Supports dependency warmup (`warmup=True`) for APP/REQUEST factories.
- Retrieve a dependency from a service via `await service.get_dependency(Type)`.

To load config from YAML, use [`YAMLConfigurationService`](https://github.com/Fatal1ty/operetta/blob/main/operetta/service/configuration.py):

```python
from operetta import Application
from operetta.service.configuration import YAMLConfigurationService

config_service = YAMLConfigurationService()  # reads --config path from CLI
app = Application(config_service)
```

Two values are provided to DI: `ApplicationDictConfig` (raw dict) and a config object (if you provide `config_cls`/`config_factory`).

Custom config class (mashumaro DataClassDictMixin):

```python
from dataclasses import dataclass
from mashumaro import DataClassDictMixin
from operetta import Application
from operetta.service.configuration import YAMLConfigurationService

# Define your typed config mapped to YAML structure
@dataclass
class AppConfig(DataClassDictMixin):
    # You can use nested dataclasses as well; here kept minimal
    creds: dict[str, str] | None = None

# Build service that parses YAML into AppConfig using mashumaro
config_service = YAMLConfigurationService(
    config_cls=AppConfig,
    config_factory=AppConfig.from_dict,
)

# Both ApplicationDictConfig (raw dict) and AppConfig are available in DI
app = Application(config_service)
```

## PostgreSQL

Operetta provides a thin, uniform abstraction over PostgreSQL so your application code does not depend on a particular driver or pool manager. You write repositories and units of work against two interfaces:

- `PostgresDatabaseAdapter` — a general-purpose adapter for any operations (fetch, fetch_one, execute, ...) without explicit transaction control.
- `PostgresTransactionDatabaseAdapter` — the same API for all operations plus transaction control methods (start/commit/rollback) when you need to run multiple steps in a single transaction.

There are two interchangeable backends:
- `asyncpg` — a straightforward single-pool setup.
- `hasql` (asyncpg HA) — a high-availability pool manager with balancing/failover.

Both backends expose the same interfaces via DI, so switching is configuration-only. DI scopes are chosen to match typical usage:
- `PostgresDatabaseAdapter` is provided with scope=APP (shared pool).
- `PostgresTransactionDatabaseAdapter` is provided with scope=REQUEST (per-request/operation handle for transactional work).

Configuration is provided via DI:
- Connection config types: `AsyncpgPostgresDatabaseConfig` (for asyncpg) and `AsyncpgHAPostgresDatabaseConfig` (for asyncpg HA).
- Pool factory kwargs type: `AsyncpgPoolFactoryKwargs` (to pass `init` or other pool options to the driver/manager).
- Built-in config providers — `AsyncpgPostgresDatabaseConfigProvider` and `AsyncpgHAPostgresDatabaseConfigProvider` — read settings from `ApplicationDictConfig['postgres']`, which is loaded by `YAMLConfigurationService` from your YAML file.
- A built-in pool kwargs provider returns an empty `AsyncpgPoolFactoryKwargs` by default; you can override it to customize connection initialization (see Advanced setup).

Typical pattern:
- Use `PostgresDatabaseAdapter` when you don't need explicit transaction management: it's suitable for any reads and writes.
- When you need transactional boundaries, get `PostgresTransactionDatabaseAdapter`, call `start_transaction()`/`commit_transaction()` (or `rollback_transaction()` on error), and run your operations within that transaction.

Configuration can be loaded from YAML via `YAMLConfigurationService` under the `postgres:` key. Optional connection initialization (e.g., custom codecs or `search_path`) can be provided through `AsyncpgPoolFactoryKwargs` in DI; this works for both `asyncpg` and `hasql` variants.

### Single-node PostgreSQL (asyncpg)

Provides:
- Providers: `AsyncpgPostgresDatabaseProvider`, `AsyncpgPostgresDatabaseConfigProvider`.
- Convenience services to plug into `Application`:
  - `AsyncpgPostgresDatabaseService` — pool and adapters,
  - `AsyncpgPostgresDatabaseConfigurationService` — loads config from `ApplicationDictConfig`.
- Adapters:
  - `PostgresDatabaseAdapter` with scope=APP — general-purpose adapter for any operations (fetch/fetch_one/execute, ...).
  - `PostgresTransactionDatabaseAdapter` with scope=REQUEST (handy for HTTP requests) — same API plus transaction control methods (start/commit/rollback).

YAML config example:

```yaml
postgres:
  user: app
  password: secret
  database: appdb
  host: 127.0.0.1:5432
  # optional pool params:
  min_size: 5
  max_size: 20
  max_queries: 50000
  max_inactive_connection_lifetime: 300
```

Plug into the app:

```python
from operetta.app import Application
from operetta.service.configuration import YAMLConfigurationService
from operetta.integrations.asyncpg.service import (
    AsyncpgPostgresDatabaseService,
    AsyncpgPostgresDatabaseConfigurationService,
)

app = Application(
    YAMLConfigurationService(),
    AsyncpgPostgresDatabaseConfigurationService(),
    AsyncpgPostgresDatabaseService(),
)
```

Use in a repository:

```python
from dataclasses import dataclass
from operetta.ddd.infrastructure.db.postgres.adapters.interface import (
    PostgresDatabaseAdapter,
    PostgresTransactionDatabaseAdapter,
)

@dataclass
class User:
    id: int
    name: str

class UserRepository:
    def __init__(self, db: PostgresDatabaseAdapter):
        self._db = db

    async def get_by_id(self, user_id: int) -> User | None:
        row = await self._db.fetch_one(
            "SELECT id, name FROM users WHERE id=$1", user_id
        )
        return User(id=row["id"], name=row["name"]) if row else None

class UnitOfWork:
    def __init__(self, tx: PostgresTransactionDatabaseAdapter):
        self._tx = tx

    async def __aenter__(self):
        await self._tx.start_transaction()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        if exc:
            await self._tx.rollback_transaction()
        else:
            await self._tx.commit_transaction()
```

### High-availability PostgreSQL cluster (hasql)

If you run an HA cluster (multiple nodes), use the hasql integration.

Provides:
- Providers: `AsyncpgHAPostgresDatabaseProvider`, `AsyncpgHAPostgresDatabaseConfigProvider`.
- Convenience services to plug into `Application`:
  - `AsyncpgHAPostgresDatabaseService` — pool and adapters,
  - `AsyncpgHAPostgresDatabaseConfigurationService` — loads config from `ApplicationDictConfig`.
- Adapters:
  - `PostgresDatabaseAdapter` with scope=APP — general-purpose adapter for any operations (fetch/fetch_one/execute, ...).
  - `PostgresTransactionDatabaseAdapter` with scope=REQUEST (handy for HTTP requests) — same API plus transaction control methods (start/commit/rollback).

YAML config example:

```yaml
postgres:
  user: app
  password: secret
  database: appdb
  hosts:
    - 10.0.0.1:5432
    - 10.0.0.2:5432
  min_masters: 1
  min_replicas: 1
  # optional:
  acquire_timeout: 5
  refresh_delay: 5
  refresh_timeout: 5
  fallback_master: false
  master_as_replica_weight: 1.0
  balancer_policy: greedy  # or round_robin / random_weighted
  stopwatch_window_size: 100
```

Plug into the app:

```python
from operetta.app import Application
from operetta.service.configuration import YAMLConfigurationService
from operetta.integrations.asyncpg_ha.service import (
    AsyncpgHAPostgresDatabaseService,
    AsyncpgHAPostgresDatabaseConfigurationService,
)

app = Application(
    YAMLConfigurationService(),
    AsyncpgHAPostgresDatabaseConfigurationService(),
    AsyncpgHAPostgresDatabaseService(),
)
```

> [!TIP]\
> DI exposes the same adapter interfaces, so repository and unit of work code stays unchanged.

### Advanced setup

You can pass an `init` callable for connections (e.g., register codecs, set search_path) via DI. Below is an example provider from a real project that registers a custom JSONB codec for asyncpg HA (hasql):

```python
import json
from dishka import Provider, Scope, provide
from operetta.app import Application
from operetta.service.configuration import YAMLConfigurationService
from operetta.integrations.asyncpg.config import AsyncpgPoolFactoryKwargs
from operetta.integrations.asyncpg_ha.service import (
    AsyncpgHAPostgresDatabaseConfigurationService,
    AsyncpgHAPostgresDatabaseService,
)

class AsyncpgJSONCodecProvider(Provider):
    scope = Scope.APP

    @provide(override=True)
    def get_pool_factory_kwargs(self) -> AsyncpgPoolFactoryKwargs:
        async def set_custom_codecs(conn):
            await conn.set_type_codec(
                "jsonb",
                encoder=json.dumps,
                decoder=json.loads,
                schema="pg_catalog",
            )
        return AsyncpgPoolFactoryKwargs(init=set_custom_codecs)

app = Application(
    YAMLConfigurationService(),
    AsyncpgHAPostgresDatabaseConfigurationService(),
    AsyncpgHAPostgresDatabaseService(),
    di_providers=[AsyncpgJSONCodecProvider()],
)
```

> [!IMPORTANT]\
> When you provide your own `AsyncpgPoolFactoryKwargs`, the provider method must be declared with `@provide(override=True)`. This overrides the built‑in default `AsyncpgPoolFactoryKwargs` provider.\
> Without `override=True`, container validation may fail.

Define your own config providers (e.g., from environment variables) if you don't want to use YAML-based ones:

```python
import os
from dishka import Provider, Scope, provide
from operetta.app import Application
from operetta.integrations.asyncpg.config import (
    AsyncpgPostgresDatabaseConfig,
    AsyncpgPoolFactoryKwargs,
)
from operetta.integrations.asyncpg.service import AsyncpgPostgresDatabaseService

class EnvAsyncpgConfigProvider(Provider):
    scope = Scope.APP

    @provide
    def get_db_config(self) -> AsyncpgPostgresDatabaseConfig:
        return AsyncpgPostgresDatabaseConfig(
            user=os.getenv("PGUSER", "app"),
            database=os.getenv("PGDATABASE", "appdb"),
            host=os.getenv("PGHOST", "127.0.0.1:5432"),
            password=os.getenv("PGPASSWORD"),
        )

    @provide(override=True)
    def get_pool_factory_kwargs(self) -> AsyncpgPoolFactoryKwargs:
        return {}

app = Application(
    AsyncpgPostgresDatabaseService(),
    di_providers=[EnvAsyncpgConfigProvider()],
)
```

Example of an environment-based HA config provider:

```python
import os
from dishka import Provider, Scope, provide
from operetta.app import Application
from operetta.integrations.asyncpg.config import AsyncpgPoolFactoryKwargs
from operetta.integrations.asyncpg_ha.config import AsyncpgHAPostgresDatabaseConfig
from operetta.integrations.asyncpg_ha.service import (
    AsyncpgHAPostgresDatabaseConfigurationService,
    AsyncpgHAPostgresDatabaseService,
)


class EnvHasqlConfigProvider(Provider):
    scope = Scope.APP

    @provide
    def get_db_config(self) -> AsyncpgHAPostgresDatabaseConfig:
        hosts = os.getenv("PGHOSTS", "10.0.0.1:5432,10.0.0.2:5432").split(",")
        return AsyncpgHAPostgresDatabaseConfig(
            user=os.getenv("PGUSER", "app"),
            database=os.getenv("PGDATABASE", "appdb"),
            hosts=[h.strip() for h in hosts if h.strip()],
            password=os.getenv("PGPASSWORD"),
            min_masters=int(os.getenv("PG_MIN_MASTERS", "1")),
            min_replicas=int(os.getenv("PG_MIN_REPLICAS", "1")),
        )

    @provide(override=True)
    def get_pool_factory_kwargs(self) -> AsyncpgPoolFactoryKwargs:
        return {}


app = Application(
    AsyncpgHAPostgresDatabaseConfigurationService(),
    AsyncpgHAPostgresDatabaseService(),
    di_providers=[EnvHasqlConfigProvider()],
)

```

## Error handling and response format

- Successful responses are automatically wrapped into `{ "success": true, "data": ..., "error": null }`.
- Errors use `{ "success": false, "data": null, "error": { message, code, details } }`.
- Standard AIOHTTP errors and domain/infrastructure errors (see `operetta.ddd.*.errors`) are mapped by middleware from `integrations/aiohttp/middlewares.py`.
- Parsing errors for body/params use types from `integrations/aiohttp/errors.py` (`InvalidJSONBodyError`, `InvalidQueryParamsError`, `InvalidPathParamsError`, ...).
